{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdd14d8a",
   "metadata": {},
   "source": [
    "Simplest simplest, let's start with a linear regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa69c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(features_df):\n",
    "    print(\"\\n--- Training and Evaluating Linear Regression Model with 10-Fold Cross-Validation ---\")\n",
    "    MIN_SAMPLES_FOR_CV = 10 \n",
    "    if features_df.empty or len(features_df) < MIN_SAMPLES_FOR_CV:\n",
    "        print(f\"Not enough data for 10-fold CV. Need {MIN_SAMPLES_FOR_CV}, found {len(features_df)}.\")\n",
    "        return\n",
    "\n",
    "    y = features_df['delta_OD']\n",
    "    X = features_df.drop(columns=['delta_OD', 'OD'])\n",
    "\n",
    "    if X.empty: print(\"No features available.\"); return\n",
    "\n",
    "    X_filled = X.fillna(X.mean())\n",
    "    if X_filled.isna().any().any():\n",
    "        cols_to_drop = X_filled.columns[X_filled.isna().all()].tolist()\n",
    "        if cols_to_drop:\n",
    "            X_filled = X_filled.drop(columns=cols_to_drop)\n",
    "            print(f\"Dropped all-NaN columns: {cols_to_drop}\")\n",
    "        if X_filled.empty or X_filled.isna().any().any() :\n",
    "             print(\"Features are still problematic after NaN handling.\"); return\n",
    "    \n",
    "    y_aligned = y.loc[X_filled.index]\n",
    "\n",
    "    pipeline = Pipeline([('scaler', StandardScaler()), ('regressor', LinearRegression())])\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    mse_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='neg_mean_squared_error', cv=cv)\n",
    "    mae_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='neg_mean_absolute_error', cv=cv)\n",
    "    r2_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='r2', cv=cv)\n",
    "\n",
    "    print(\"\\nCross-Validation Model Evaluation Metrics (10-fold):\")\n",
    "    print(f\"  Mean Squared Error (MSE): {-np.mean(mse_scores):.4f} (+/- {np.std(mse_scores):.4f})\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {np.sqrt(-np.mean(mse_scores)):.4f}\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {-np.mean(mae_scores):.4f} (+/- {np.std(mae_scores):.4f})\")\n",
    "    print(f\"  R-squared (R²): {np.mean(r2_scores):.4f} (+/- {np.std(r2_scores):.4f})\")\n",
    "\n",
    "    # Get cross-validated predictions for plotting\n",
    "    delta_od_cv_predictions = cross_val_predict(pipeline, X_filled, y_aligned, cv=cv)\n",
    "\n",
    "    # --- Parity Plot ---\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(y_aligned, delta_od_cv_predictions, alpha=0.7, edgecolors='k')\n",
    "    min_val = min(y_aligned.min(), delta_od_cv_predictions.min())\n",
    "    max_val = max(y_aligned.max(), delta_od_cv_predictions.max())\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2) # y=x line\n",
    "    plt.xlabel(\"Actual delta_OD\")\n",
    "    plt.ylabel(\"Predicted delta_OD (Cross-Validated)\")\n",
    "    plt.title(\"Parity Plot: Actual vs. Predicted delta_OD\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # --- OD Time Course Plot ---\n",
    "    # The first actual OD value *before* any deltas in features_df\n",
    "    # OD_current = OD_previous + delta_OD  => OD_previous = OD_current - delta_OD\n",
    "    initial_actual_od_for_course = features_df['OD'].iloc[0] - features_df['delta_OD'].iloc[0]\n",
    "\n",
    "    # Actual OD course\n",
    "    actual_od_course = np.concatenate(([initial_actual_od_for_course], features_df['OD'].values))\n",
    "    \n",
    "    # Predicted OD course (reconstructed)\n",
    "    predicted_od_course = [initial_actual_od_for_course]\n",
    "    current_predicted_od = initial_actual_od_for_course\n",
    "    for pred_delta in delta_od_cv_predictions:\n",
    "        current_predicted_od += pred_delta\n",
    "        predicted_od_course.append(current_predicted_od)\n",
    "    predicted_od_course = np.array(predicted_od_course)\n",
    "\n",
    "    # Timestamps for plotting\n",
    "    # Need one timestamp before the first one in features_df.index\n",
    "    plot_timestamps = features_df.index\n",
    "    if len(plot_timestamps) > 1:\n",
    "        time_diff = plot_timestamps[1] - plot_timestamps[0]\n",
    "        initial_timestamp = plot_timestamps[0] - time_diff\n",
    "    else: # Fallback if only one delta_OD point (so one timestamp in features_df)\n",
    "        initial_timestamp = plot_timestamps[0] - pd.Timedelta(hours=1) # Arbitrary fallback\n",
    "\n",
    "    full_plot_timestamps = pd.to_datetime([initial_timestamp] + plot_timestamps.tolist())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(full_plot_timestamps, actual_od_course, label='Actual OD', marker='o', linestyle='-')\n",
    "    plt.plot(full_plot_timestamps, predicted_od_course, label='Predicted OD (Reconstructed from CV deltas)', marker='x', linestyle='--')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Optical Density (OD)\")\n",
    "    plt.title(\"Actual vs. Reconstructed Predicted OD Time Course\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # --- Feature Importance (from model trained on all data) ---\n",
    "    print(\"\\n--- Training Final Model on All Data for Feature Importance ---\")\n",
    "    pipeline.fit(X_filled, y_aligned)\n",
    "    coefficients_scaled = pipeline.named_steps['regressor'].coef_\n",
    "    feature_names = X_filled.columns\n",
    "    coefficients_df = pd.DataFrame(coefficients_scaled, feature_names, columns=['Coefficient'])\n",
    "    sorted_coefficients = coefficients_df.reindex(coefficients_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "    print(\"\\nFeature Importance (Coefficients from model trained on all data, features were scaled):\")\n",
    "    print(sorted_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d70f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(features_df):\n",
    "    print(\"\\n--- Training and Evaluating Linear Regression Model with 10-Fold Cross-Validation ---\")\n",
    "    # For 10-fold CV, we need at least 10 samples.\n",
    "    MIN_SAMPLES_FOR_CV = 10 \n",
    "    if features_df.empty or len(features_df) < MIN_SAMPLES_FOR_CV:\n",
    "        print(f\"Not enough data for 10-fold cross-validation. Need at least {MIN_SAMPLES_FOR_CV} samples, found {len(features_df)}.\")\n",
    "        return\n",
    "\n",
    "    y = features_df['delta_OD']\n",
    "    X = features_df.drop(columns=['delta_OD', 'OD'])\n",
    "\n",
    "    if X.empty:\n",
    "        print(\"No features available. Cannot train model.\")\n",
    "        return\n",
    "\n",
    "    X_filled = X.fillna(X.mean())\n",
    "    if X_filled.isna().any().any():\n",
    "        print(\"Warning: NaN values still present in features after mean imputation. Dropping these columns.\")\n",
    "        cols_to_drop = X_filled.columns[X_filled.isna().all()].tolist()\n",
    "        X_filled = X_filled.drop(columns=cols_to_drop)\n",
    "        if X_filled.empty:\n",
    "            print(\"No features left after dropping all-NaN columns. Cannot train model.\")\n",
    "            return\n",
    "        print(f\"Dropped all-NaN columns: {cols_to_drop}\")\n",
    "    \n",
    "    # Align y with X_filled in case any rows were dropped (though fillna shouldn't drop rows)\n",
    "    # However, if X_filled becomes empty or significantly changes shape, y needs to align.\n",
    "    # This alignment is crucial if X_filled.dropna() were used. With fillna, index should remain.\n",
    "    y_aligned = y.loc[X_filled.index]\n",
    "\n",
    "\n",
    "    # Create a pipeline that first scales the data then applies linear regression\n",
    "    pipeline = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    # Define the K-fold cross-validator\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation for different metrics\n",
    "    # Note: cross_val_score returns negative MSE and MAE, so we'll flip the sign\n",
    "    mse_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='neg_mean_squared_error', cv=cv)\n",
    "    mae_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='neg_mean_absolute_error', cv=cv)\n",
    "    r2_scores = cross_val_score(pipeline, X_filled, y_aligned, scoring='r2', cv=cv)\n",
    "\n",
    "    # Calculate and print mean and std dev of the metrics\n",
    "    mean_mse = -np.mean(mse_scores)\n",
    "    std_mse = np.std(mse_scores)\n",
    "    mean_rmse = np.sqrt(mean_mse) # RMSE from mean MSE\n",
    "    mean_mae = -np.mean(mae_scores)\n",
    "    std_mae = np.std(mae_scores)\n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "\n",
    "    print(\"\\nCross-Validation Model Evaluation Metrics (10-fold):\")\n",
    "    print(f\"  Mean Squared Error (MSE): {mean_mse:.4f} (+/- {std_mse:.4f})\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {mean_rmse:.4f} (derived from mean MSE)\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mean_mae:.4f} (+/- {std_mae:.4f})\")\n",
    "    print(f\"  R-squared (R²): {mean_r2:.4f} (+/- {std_r2:.4f})\")\n",
    "\n",
    "    # For feature importance, train the final model on all available data\n",
    "    print(\"\\n--- Training Final Model on All Data for Feature Importance ---\")\n",
    "    pipeline.fit(X_filled, y_aligned)\n",
    "    \n",
    "    # Extract coefficients from the regressor step in the pipeline\n",
    "    # The scaler step in the pipeline already scaled the features\n",
    "    coefficients_scaled = pipeline.named_steps['regressor'].coef_\n",
    "    \n",
    "    feature_names = X_filled.columns\n",
    "    coefficients_df = pd.DataFrame(coefficients_scaled, feature_names, columns=['Coefficient'])\n",
    "    \n",
    "    # Sort by absolute magnitude to see strongest impacts\n",
    "    sorted_coefficients = coefficients_df.reindex(coefficients_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "    \n",
    "    print(\"\\nFeature Importance (Coefficients from model trained on all data, features were scaled):\")\n",
    "    print(sorted_coefficients)\n",
    "    print(\"\\nNote: Coefficients represent the change in delta_OD for a one-unit change in the (scaled) feature.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787047c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training and Evaluating Linear Regression Model with 10-Fold Cross-Validation ---\n",
      "\n",
      "Cross-Validation Model Evaluation Metrics (10-fold):\n",
      "  Mean Squared Error (MSE): 0.0018 (+/- 0.0055)\n",
      "  Root Mean Squared Error (RMSE): 0.0429 (derived from mean MSE)\n",
      "  Mean Absolute Error (MAE): 0.0044 (+/- 0.0093)\n",
      "  R-squared (R²): -400.7283 (+/- 1199.9058)\n",
      "\n",
      "--- Training Final Model on All Data for Feature Importance ---\n",
      "\n",
      "Feature Importance (Coefficients from model trained on all data, features were scaled):\n",
      "                                           Coefficient\n",
      "std_pH                                   -7.987909e-01\n",
      "min_pH                                   -4.222010e-01\n",
      "mean_pH                                   3.965542e-01\n",
      "first_last_diff_pH                       -7.274191e-02\n",
      "mean_temperature (C)                      5.049678e-02\n",
      "median_pH                                 4.581971e-02\n",
      "median_temperature (C)                   -2.533162e-02\n",
      "max_pH                                   -2.039574e-02\n",
      "min_temperature (C)                      -1.426149e-02\n",
      "max_temperature (C)                      -1.028326e-02\n",
      "std_dO                                    8.293352e-03\n",
      "min_dO                                    5.497594e-03\n",
      "mean_dO                                  -5.020323e-03\n",
      "first_last_diff_temperature (C)          -3.559841e-03\n",
      "median_dO                                -4.015094e-04\n",
      "first_last_diff_dO                       -3.095302e-04\n",
      "max_dO                                   -1.291429e-04\n",
      "std_temperature (C)                       5.622298e-05\n",
      "std_light_intensity (lumens)              2.271710e-05\n",
      "min_light_intensity (lumens)              2.063527e-05\n",
      "mean_light_intensity (lumens)            -1.795869e-05\n",
      "median_light_intensity (lumens)           1.790073e-05\n",
      "max_light_intensity (lumens)             -9.084688e-06\n",
      "first_last_diff_light_intensity (lumens) -6.542005e-06\n",
      "Unnamed: 0                                8.524670e-10\n",
      "\n",
      "Note: Coefficients represent the change in delta_OD for a one-unit change in the (scaled) feature.\n"
     ]
    }
   ],
   "source": [
    "summary_statistics_df = pd.read_csv('cyano_culture_datasets/04-15-2025 culture/combined_dataset_summary_statistics.csv')\n",
    "train_and_evaluate_model(summary_statistics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded05d99",
   "metadata": {},
   "source": [
    "# Shall we throw a 1D-CNN at it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d4eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ethical_necromancy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
